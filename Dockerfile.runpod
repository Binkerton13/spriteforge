FROM nvidia/cuda:12.1.1-cudnn8-runtime-ubuntu22.04

# Build-time flag: set to 0 for CPU-only test builds (local machines w/o NVIDIA)
ARG USE_CUDA=1

ENV DEBIAN_FRONTEND=noninteractive \
    TZ=Etc/UTC \
    WORKSPACE=/workspace \
    PORT=8188 \
    MODEL_DOWNLOAD_ON_START=0 \
    MODEL_URLS=""

# Minimal runtime packages. Include build tools so we can install latest transformers from source.
RUN apt-get update && apt-get install -y --no-install-recommends \
    git git-lfs \
    curl ca-certificates \
    ffmpeg \
    python3 python3-venv python3-pip python3-dev \
    build-essential \
    unzip \
    libgl1 libglib2.0-0 libxrender1 libxext6 libsm6 \
    libx11-6 libxi6 libxrandr2 libxxf86vm1 libxfixes3 libxcursor1 libxinerama1 \
    && rm -rf /var/lib/apt/lists/*

RUN git lfs install --system || true

RUN mkdir -p ${WORKSPACE}
WORKDIR ${WORKSPACE}

# Create Python venv and install runtime Python deps (torch install varies by USE_CUDA)
RUN python3 -m venv /opt/venv && \
    /opt/venv/bin/pip install --upgrade pip wheel setuptools

ENV VIRTUAL_ENV=/opt/venv
ENV PATH="${VIRTUAL_ENV}/bin:${PATH}"

# Create non-root user early and make venv/workspace writable by it
RUN groupadd -r app || true && useradd -r -m -g app app || true
RUN chown -R app:app ${VIRTUAL_ENV} ${WORKSPACE} || true


RUN if [ "${USE_CUDA}" = "1" ]; then \
        pip install --no-cache-dir torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121; \
    else \
        pip install --no-cache-dir torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu; \
    fi

USER app
RUN pip install --no-cache-dir numpy scipy pillow opencv-python matplotlib scikit-image scikit-learn trimesh pygltflib huggingface_hub flask supervisor && \
    pip install --no-cache-dir --upgrade git+https://github.com/huggingface/transformers.git

# Create workspace scaffold (empty) — expect repos/models to be mounted at runtime
RUN mkdir -p ${WORKSPACE}/models/checkpoints \
             ${WORKSPACE}/models/loras \
             ${WORKSPACE}/models/vae \
             ${WORKSPACE}/models/controlnet \
             ${WORKSPACE}/models/unet \
             ${WORKSPACE}/models/3d \
             ${WORKSPACE}/models/textures \
             ${WORKSPACE}/models/rigged \
             ${WORKSPACE}/renders \
             ${WORKSPACE}/animations \
             ${WORKSPACE}/scripts

# Add a lightweight start script that will run `git lfs pull` in any cloned repos
# Place the start script in /usr/local/bin so a host mount of /workspace doesn't
# hide or remove it at runtime.
# Also copy file browser and supervisor config
COPY file_browser.py /usr/local/bin/file_browser.py
COPY supervisord.conf /etc/supervisord.conf
RUN chmod +x /usr/local/bin/file_browser.py

RUN printf '%s\n' "#!/usr/bin/env bash" \
    "set -e" \
    "source \"${VIRTUAL_ENV}/bin/activate\"" \
    "if [ \"\${MODEL_DOWNLOAD_ON_START:-0}\" = \"1\" ]; then" \
    "  echo \"MODEL_DOWNLOAD_ON_START=1: downloading configured model URLs\"" \
    "  if [ -n \"\${MODEL_URLS}\" ]; then" \
    "    echo \"\${MODEL_URLS}\" | tr \",\" '\\n' | while read url; do" \
    "      url=\"\$(echo \"\$url\" | xargs)\"" \
    "      if [ -n \"\$url\" ]; then" \
    "        fname=\"\$(basename \"\$url\")\"" \
    "        mkdir -p /workspace/models/3d" \
    "        curl -L --retry 3 -o \"/workspace/models/3d/\$fname\" \"\$url\" || echo \"download failed: \$url\"" \
    "      fi" \
    "    done" \
    "  fi" \
    "fi" \
    "for repo in comfyui unirig triposr hy-motion; do" \
    "  if [ -d \"/workspace/$repo/.git\" ]; then" \
    "    echo \"Running git lfs pull in /workspace/$repo\"" \
    "    git -C \"/workspace/$repo\" lfs pull || true" \
    "  fi" \
    "done" \
    "python - <<EOF" \
    "import torch" \
    "print(\"CUDA available:\", torch.cuda.is_available())" \
    "print(\"Device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\")" \
    "EOF" \
    "echo \"Starting ComfyUI on port \${PORT:-8188} and File Browser on port 8080\"" \
    "if [ -d \"/workspace/comfyui\" ]; then" \
    "  exec supervisord -c /etc/supervisord.conf" \
    "else" \
    "  echo \"No /workspace/comfyui present; mount your ComfyUI repo to /workspace/comfyui\"" \
    "  tail -f /dev/null" \
    "fi" \
    > /usr/local/bin/start.sh && chmod +x /usr/local/bin/start.sh

USER app

EXPOSE 8188 8080

HEALTHCHECK --interval=30s --timeout=5s --start-period=30s --retries=3 \
  CMD curl -fsS http://127.0.0.1:${PORT:-8188}/ || exit 1

CMD ["/bin/bash", "/usr/local/bin/start.sh"]

# Ensure latest transformers is present — reinstall from GitHub after other
# pip installs so requirements files do not downgrade it.
USER root
RUN ${VIRTUAL_ENV}/bin/pip install --no-cache-dir --upgrade git+https://github.com/huggingface/transformers.git || true
RUN chown -R app:app ${VIRTUAL_ENV} ${WORKSPACE} || true
USER app
